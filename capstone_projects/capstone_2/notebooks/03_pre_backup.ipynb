{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e83bfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3.0 Pre-processing and Training\n",
    "\n",
    "Contents\n",
    "\n",
    "3.1 [Introduction](#3.1)\n",
    "\n",
    "  * [3.1.1 Problem Recap](#3.1.1)\n",
    "  * [3.1.2 Notebook Goals](#3.1.2)\n",
    " \n",
    "   \n",
    "3.2 [Load the data](#3.2)\n",
    "\n",
    "  * [3.2.1 Imports](#3.2.1)\n",
    "  * [3.2.2 Load the data](#3.2.2)\n",
    "\n",
    "\n",
    "3.4 [Pre-processing](#3.4)\n",
    "\n",
    "  * [3.4.1 Examine Positive/Negative Split](#3.4.1)\n",
    "  * [3.4.2 Set Random Seed for Reproducability](#3.4.2)\n",
    "  * [3.4.3 Train/test Split](#3.4.3)\n",
    "\n",
    "3.5 [Vectorizing the Text](#3.5)\n",
    "\n",
    "  * [3.5.1 Count Vectorization](#3.5.1)\n",
    "  * [3.5.2 Term-Frequency Inverse-Document Frequency](#3.5.2)\n",
    "\n",
    "3.6 [Building a Simple Model](#3.6)\n",
    "<br/><br/>\n",
    "  * 3.6.1 [Logistic Regression](#3.6.1)\n",
    "<br/><br/>\n",
    "    * [3.6.1.1 Training the Model](#3.6.1.1)\n",
    "    * [3.6.1.2 Fitting the Model](#3.6.1.2)\n",
    "    * [3.6.1.3 Evaluating the Model](#3.6.1.3)\n",
    "<br/><br/>\n",
    "  * 3.6.2 [Naive Bayes](#3.6.2)\n",
    "<br/> <br/> \n",
    "    * [3.6.2.1 Training the Model](#3.6.1.1)\n",
    "    * [3.6.2.2 Fitting the Model](#3.6.2.2)\n",
    "    * [3.6.2.3 Evaluating the Model](#3.6.2.3)\n",
    "<br/> <br/>\n",
    "  * 3.6.3 [SVM Classifier](#3.6.3)\n",
    "<br/>  <br/>\n",
    "    * [3.6.3.1 Training the Model](#3.6.3.1)\n",
    "    * [3.6.3.2 Fitting the Model](#3.6.3.2)\n",
    "    * [3.6.3.3 Evaluating the Model](#3.6.3.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9c841",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 Introduction <a name=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d02b97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1.1 Problem Recap <a name=\"3.1.1\"><a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cadbd87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using customer text data about amazon products, we will build, evaluate and compare models to estimate the probability that a given text review can be classified as “positive” or “negative”.\n",
    "\n",
    "Our goal is to build a text classifier using Amazon product review data which can be used to analyze customer sentiment which does not have accompanying numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc4983",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1.2 Notebook Goals <a name=\"3.1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda4730",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Normalize the text using lemmatization to convert different forms of the same word to the same stem where possible.\n",
    "\n",
    "\n",
    "2. Split the data into train and test sets.\n",
    "\n",
    "3. Convert our text review data into numeric features. (CountVectorization, TFIDF, and word2vec are options)\n",
    "\n",
    "4. Build a simple, initial predictive model using Logistic Regression. \n",
    "\n",
    "5. Logistic Regression predicts probabilities. With \"positive\" (0) and \"negative\" (1) review, we can do a binary classification.\n",
    "\n",
    "6. Measure the performance of the model with a Classification Report, Confusion Matrix and ROC + AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d646fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Load the data <a name=\"3.2\"><a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718e2c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2.1 Imports <a name=\"3.2.1\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589120c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "from spacy.lang.en import English\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041448da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2.2 Load the data <a name=\"3.2.2\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d6a53a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pq.read_table(\"../data/edited/fashion.parquet\")\n",
    "fashion = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4d67c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exactly needed</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agree review opening small bent hook expensiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love going order pack work including losing ea...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiny opening</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  neg_sentiment  stars  \\\n",
       "0                                     exactly needed              0      5   \n",
       "1   agree review opening small bent hook expensiv...              1      2   \n",
       "2  love going order pack work including losing ea...              0      4   \n",
       "3                                       tiny opening              1      2   \n",
       "4                                               okay              1      3   \n",
       "\n",
       "   review_length  \n",
       "0              4  \n",
       "1             49  \n",
       "2             50  \n",
       "3              4  \n",
       "4              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f498bccd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>873352.000000</td>\n",
       "      <td>873352.000000</td>\n",
       "      <td>873352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.304939</td>\n",
       "      <td>3.904786</td>\n",
       "      <td>29.131591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.460382</td>\n",
       "      <td>1.419361</td>\n",
       "      <td>39.372047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2196.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       neg_sentiment          stars  review_length\n",
       "count  873352.000000  873352.000000  873352.000000\n",
       "mean        0.304939       3.904786      29.131591\n",
       "std         0.460382       1.419361      39.372047\n",
       "min         0.000000       1.000000       1.000000\n",
       "25%         0.000000       3.000000       7.000000\n",
       "50%         0.000000       5.000000      17.000000\n",
       "75%         1.000000       5.000000      36.000000\n",
       "max         1.000000       5.000000    2196.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e57eb28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873352, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b279c482",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f985033",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3.1 Examine Positive/Negative Split <a name=\"3.3.1\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10a27b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 as positive reviews, 1 as negative\n",
      "\n",
      "0    607033\n",
      "1    266319\n",
      "Name: neg_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"0 as positive reviews, 1 as negative\")\n",
    "print()\n",
    "print(fashion[\"neg_sentiment\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f25d85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8332659",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fashion[\"review\"], fashion[\"neg_sentiment\"], test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947f921",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a53ec675",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4.1 Set Random Seed for Reproducability <a name=\"3.3.2\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c521e2ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196a8de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4.2 Train/Test Split <a name=\"3.3.3\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3cf2f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    546209\n",
       "1    239807\n",
       "Name: neg_sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d08d057b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60824\n",
       "1    26512\n",
       "Name: neg_sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8331280",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' not big'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/paul/Desktop/springboard/capstone_projects/capstone_2/notebooks/03_Preprocessing_and_Training.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/paul/Desktop/springboard/capstone_projects/capstone_2/notebooks/03_Preprocessing_and_Training.ipynb#ch0000025?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(max_iter \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1509\u001b[0m     X,\n\u001b[1;32m   1510\u001b[0m     y,\n\u001b[1;32m   1511\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1512\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1513\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1514\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1515\u001b[0m )\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.10/site-packages/sklearn/base.py:576\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    575\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    577\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.10/site-packages/sklearn/utils/validation.py:956\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 956\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    957\u001b[0m     X,\n\u001b[1;32m    958\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    959\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    961\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    962\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    963\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    964\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    965\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    966\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    967\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    968\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    969\u001b[0m )\n\u001b[1;32m    971\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    973\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.10/site-packages/sklearn/utils/validation.py:738\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    736\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    737\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    739\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    740\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    741\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    742\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.10/site-packages/pandas/core/series.py:872\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    826\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[39m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ' not big'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e60ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3654b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786016,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8cee6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764223629035541"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "688882/786016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1335144",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37e746",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87336,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_preds == y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707416e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76338"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_preds == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382421b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740725474031328"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "76338/87336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5ba6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.5 Initial Modeling <a name=\"3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341e647",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d684fec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942f945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00999230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d73df188c3ed28f9117694899638a2078581279f5400990dc36b7edf848ab19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
